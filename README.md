# NFT Data Pipeline Take-Home Assignment

## Objective
Build a scalable data pipeline that processes NFT transfer events to generate insights using dbt. The assignment should take 3-4 hours.

## Core Requirements (Mandatory)

### 1. Data Analysis
- Calculate current NFT ownership per wallet based on transfer history
- Compute unique NFT collections each wallet has interacted with
- Identify power users (wallets with >50 transfer events)

### 2. Technical Implementation
- Use dbt for transformations
- Implement incremental processing
- Write optimized SQL queries and add more migrations to the schema where required
- Add tests to validate your implementation
- Document models using dbt schema.yml files

### 3. Deliverables
- Git repository with complete code
- Clear documentation of design decisions and assumptions
- Setup and testing instructions

## Extended Tasks (Optional)
If time permits, attempt any of these:
- Performance optimization strategies
- Monitoring and alerting design
- Identity resolution for wallet clustering
- CI/CD pipeline setup

## Evaluation Criteria
- SQL expertise and query optimization
- Data modeling design
- Testing and data quality approach
- Documentation clarity
- Incremental processing implementation

## Submission
- Submit via Git repository
- Document any assumptions made
- Note which extended tasks you attempted (if any)

Remember to focus on quality over quantity. It's better to complete core requirements well than to attempt everything superficially.